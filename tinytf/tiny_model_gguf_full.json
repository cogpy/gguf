{"metadata": {"Model_Architecture": "TinyTransformer", "Context_Length": 5, "Embedding_Length": 5, "Block_Count": 1, "Feed_Forward_Layer_Size": 5, "RoPE_Dimension_Count": 5, "Attention_Head_Count": 1, "Layer_Norm_Epsilon": 1e-05, "RoPE_Frequency_Base": 10000, "File_Type": 2}, "vocab": {"vocab": {"0": "token_0", "1": "token_1", "2": "token_2", "3": "token_3", "4": "token_4", "5": "token_5", "6": "token_6", "7": "token_7", "8": "token_8", "9": "token_9"}}, "nodes": {"embedding": {"type": "embedding", "input_dim": 10, "output_dim": 5, "weights": "binary: tiny_model_weights.bin"}, "attention": {"type": "self_attention", "input_dim": 5, "num_heads": 1, "weights": "binary: tiny_model_weights.bin"}, "feedforward": {"type": "feedforward", "input_dim": 5, "output_dim": 5, "weights": "binary: tiny_model_weights.bin"}, "output": {"type": "linear", "input_dim": 5, "output_dim": 10, "weights": "binary: tiny_model_weights.bin"}}, "edges": {"embedding_to_attention": {"from": "embedding", "to": "attention"}, "attention_to_feedforward": {"from": "attention", "to": "feedforward"}, "feedforward_to_output": {"from": "feedforward", "to": "output"}}}